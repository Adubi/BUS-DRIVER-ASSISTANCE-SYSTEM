{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuLasjzKuuAsDL+lwLbVFN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adubi/BUS-DRIVER-ASSISTANCE-SYSTEM/blob/main/AUTONOMOUS_PUBLIC_BUS_DRIVER_ASSISTANCE_SYSTEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OBJECT DETECTION"
      ],
      "metadata": {
        "id": "vTqybf4Wc81J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bmfGhbvTmh5"
      },
      "outputs": [],
      "source": [
        "# Load video from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -U --no-cache-dir"
      ],
      "metadata": {
        "id": "ZH1R_4jJ2s22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "!gdown 13Xvx-fZJb55vvT9tGaAa6ijE6fHgYIkl"
      ],
      "metadata": {
        "id": "7znhi0Ou31a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "LxpTXan84t29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the video\n",
        "!gdown 1JXsAxKjfTeBNvYRCV9ew1mAMccNklH4s"
      ],
      "metadata": {
        "id": "6EVOD8kF5T-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "!pip install tqdm --upgrade\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Create folder in colab\n",
        "train_path_img = \"./yolo_data/images/train/\"\n",
        "train_path_label = \"./yolo_data/labels/train/\"\n",
        "val_path_img = \"./yolo_data/images/val/\"\n",
        "val_path_label = \"./yolo_data/labels/val/\"\n",
        "test_path = \"./yolo_data/test\"\n",
        "\n",
        "'''\n",
        "Split the dataset into train and test and creates the train.txt and test.tx with\n",
        "the respective path of the images in each folder\n",
        "'''\n",
        "\n",
        "def train_test_split(path,neg_path=None, split = 0.2):\n",
        "    print(\"------ PROCESS STARTED -------\")\n",
        "\n",
        "\n",
        "    files = list(set([name[:-4] for name in os.listdir(path)])) ## removing duplicate names i.e. counting only number of images\n",
        "\n",
        "\n",
        "    print (f\"--- This folder has a total number of {len(files)} images---\")\n",
        "    random.seed(42)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    test_size = int(len(files) * split)\n",
        "    train_size = len(files) - test_size\n",
        "\n",
        "    ## creating required directories\n",
        "\n",
        "    os.makedirs(train_path_img, exist_ok = True)\n",
        "    os.makedirs(train_path_label, exist_ok = True)\n",
        "    os.makedirs(val_path_img, exist_ok = True)\n",
        "    os.makedirs(val_path_label, exist_ok = True)\n",
        "\n",
        "\n",
        "    ### ----------- copying images to train folder\n",
        "    for filex in tqdm(files[:train_size]):\n",
        "      if filex == 'classes':\n",
        "          continue\n",
        "      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n",
        "      shutil.copy2(path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n",
        "\n",
        "    print(f\"------ Training data created with 80% split {len(files[:train_size])} images -------\")\n",
        "\n",
        "    if neg_path:\n",
        "        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n",
        "        for filex in tqdm(neg_images):\n",
        "            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n",
        "\n",
        "        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n",
        "\n",
        "        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n",
        "\n",
        "    # copying images to validation folder\n",
        "    for filex in tqdm(files[train_size:]):\n",
        "      if filex == 'classes':\n",
        "          continue\n",
        "      # print(\"running\")\n",
        "      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n",
        "      shutil.copy2(path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n",
        "\n",
        "    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n",
        "\n",
        "    print(\"------ TASK COMPLETED -------\")\n",
        "\n",
        "## spliting the data into train-test and creating train.txt and test.txt files\n",
        "train_test_split('/content/data/') # change to your dataset folder"
      ],
      "metadata": {
        "id": "ghBetN8z5f5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kanyakornju/speed-prediction.git\n",
        "%cd /content/speed-prediction/object-detection\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ul1LdWaaAOVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py"
      ],
      "metadata": {
        "id": "9gbqk3lL9x_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --epochs 2 --data dataset.yaml --cfg yolov5s.yaml"
      ],
      "metadata": {
        "id": "89WS7KFXDL9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --save-txt --weights runs/train/exp2/weights/best.pt --conf 0.6 --source '/content/speed-prediction/object-detection/VID-20230217-WA0000.mp4'"
      ],
      "metadata": {
        "id": "vs1riXcjVO6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OBJ DETECTION MODEL EVAUATION\n"
      ],
      "metadata": {
        "id": "uC2AqqJBqnMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Check this directory for results of experiments i.e recall curve, confusion matrix e.t.c /content/speed-prediction/object-detection/runs/train/exp\n"
      ],
      "metadata": {
        "id": "1V4pd250qlqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DISTANCE ESTIMATION"
      ],
      "metadata": {
        "id": "7fTQlHATwx21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speed-prediction/distance-estimation\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "NDY686uTwKez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATE TRAIN-TEST DATASET FOR DISTANCE ESTIMATION FROM annotations.csv TO BE USED FOR TRAINING ON KITTI DATASET MODEL"
      ],
      "metadata": {
        "id": "hA_qMSCvRYEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Generate train-test dataset for distance estimation\n",
        "'''\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('annotations.csv')\n",
        "df = df.dropna()\n",
        "new_df = df.loc[df['class'] != 'DontCare']\n",
        "result_df = pd.DataFrame(columns=['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax', \\\n",
        "                           'angle', 'xloc', 'yloc', 'zloc'])\n",
        "\n",
        "pbar = tqdm(total=new_df.shape[0], position=1)\n",
        "\n",
        "for idx, row in new_df.iterrows():\n",
        "    pbar.update(1)\n",
        "    result_df.at[idx, 'filename'] = row['filename']\n",
        "    result_df.at[idx, 'class'] = row['class']\n",
        "\n",
        "    result_df.at[idx, 'xmin'] = int(row['xmin'])\n",
        "    result_df.at[idx, 'ymin'] = int(row['ymin'])\n",
        "    result_df.at[idx, 'xmax'] = int(row['xmax'])\n",
        "    result_df.at[idx, 'ymax'] = int(row['ymax'])\n",
        "\n",
        "    result_df.at[idx, 'angle'] = row['observation angle']\n",
        "    result_df.at[idx, 'xloc'] = int(row['xloc'])\n",
        "    result_df.at[idx, 'yloc'] = int(row['yloc'])\n",
        "    result_df.at[idx, 'zloc'] = int(row['zloc'])\n",
        "\n",
        "mask = np.random.rand(len(result_df)) < 0.9\n",
        "train = result_df[mask]\n",
        "test = result_df[~mask]\n",
        "\n",
        "train.to_csv('train.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)"
      ],
      "metadata": {
        "id": "t_z6vJE7Q4Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"Train the distance estimation model\"\n",
        "!python train.py --results models/ --train train.csv --test test.csv"
      ],
      "metadata": {
        "id": "dDtsY8WFUPhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGE model(.json) AND weights(.h5) TO YOUR MODEL NAME FROM \"distance-estimation/models\" FOLDER"
      ],
      "metadata": {
        "id": "lNmkLvMJVVfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''if you want to continue to train the model'''\n",
        "#!python training_continuer.py --model /content/vehicle-distance-estimation/distance-estimator/models/model@1681254624.json --weights /content/vehicle-distance-estimation/distance-estimator/models/model@1681254624.h5"
      ],
      "metadata": {
        "id": "sS-M4f-7UoVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python plot_history.py --filename models/model@1682174488_results.csv"
      ],
      "metadata": {
        "id": "r69_oDm1XRg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --data /content/speed-prediction/object-detection/results/data/data.csv --model models/model@1682174488.json --weights models/model@1682174488.h5 --results /content/speed-prediction/distance-estimation"
      ],
      "metadata": {
        "id": "Agiujw62aseE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO VISUALIZE THE DISTANCE IN THE VIDEO\n"
      ],
      "metadata": {
        "id": "98Nxyla-bNAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python visualizer.py --data /content/speed-prediction/distance-estimation/predictions.csv --frames /content/speed-prediction/object-detection/results/frames -fps 30 --results /content/speed-prediction/distance-estimation"
      ],
      "metadata": {
        "id": "u0kjTKk_bCHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTANT NOTE: If the video is too big it cannot visualize, you can use the code below to zip your image and use python code to create the video. If you just want to see the result in your image go to '/content/vehicle-distance-estimation/object-detector/results/frames' folder in your colab"
      ],
      "metadata": {
        "id": "0lDYijO_cLKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/frames.zip /content/speed-prediction/object-detection/results/frames"
      ],
      "metadata": {
        "id": "TrIf_TlXbo1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPEED ESTIMATION"
      ],
      "metadata": {
        "id": "rRxLZ74AcpUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/speed-prediction/speed-estimation"
      ],
      "metadata": {
        "id": "VGg61XPEcwOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1ZqjwCGR3as00ut_EZkyO5U0kZ5WcSLaW\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "yvl1o3cdnFKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python opticalflow.py --test /content/VID-20230217-WA0000.mp4"
      ],
      "metadata": {
        "id": "gDTKteKPnny7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "id": "6LS41XeunrVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --test /content/VID-20230217-WA0000.mp4"
      ],
      "metadata": {
        "id": "z3y4jk-anyVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Open the input file and read the contents\n",
        "with open('/content/speed-prediction/speed-estimation/data/test.txt', 'r') as file:\n",
        "    contents = file.read().splitlines()\n",
        "\n",
        "# Create a list of tuples where the first element is the frame number and the second is the speed value\n",
        "data = [(i+1, float(speed)) for i, speed in enumerate(contents)]\n",
        "\n",
        "# Open the output file and create a CSV writer object\n",
        "with open('speed.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['frame', 'Speed'])\n",
        "\n",
        "    # Write each row of data to the file\n",
        "    for row in data:\n",
        "        writer.writerow(row)\n",
        "\n",
        "# merged two dataframe\n",
        "df1 = pd.read_csv('/content/speed-prediction/distance-estimation/predictions.csv') # replace with your own dataset filename\n",
        "df2 = pd.read_csv('speed.csv') # replace with your own dataset filename\n",
        "\n",
        "merged_df = pd.merge(df1, df2, on='frame')\n",
        "merged_df.to_csv('/content/speed_test.csv', index=False)"
      ],
      "metadata": {
        "id": "3CbN7lorn7DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPEED PREDICTION"
      ],
      "metadata": {
        "id": "3Dc4jNt9oKGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "JfYwdINsoTUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/speed_test.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DXVN5f1XovuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "ysqFQjOnozzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].replace(['car','zebra crossing','human','bus stop'], [0,1,2,3])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pE-COmSOo3ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].map({0:'car', 1:'zebra crossing', 2:'human', 3:'bus stop'})\n",
        "df = pd.get_dummies(df, columns = ['label'], prefix=' ',prefix_sep=' ')\n",
        "df.insert (13, \"bus stop\", 0)\n",
        "df = df.drop('frame', axis =1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "W4TtiUSfo6-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.sample(frac=0.8, random_state = 0)\n",
        "test_df = df.drop(train_df.index)"
      ],
      "metadata": {
        "id": "qwhla_1qpEvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "dGlhTz1cpEse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "Ng8acz4WpEpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_df.copy()\n",
        "test_features = test_df.copy()\n",
        "x_train, y_train = train_df.drop('Speed', axis=1), train_df['Speed']\n",
        "x_test, y_test = test_df.drop('Speed', axis=1), test_df['Speed']"
      ],
      "metadata": {
        "id": "fIjNYyZwpEm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_datasets(x_train, x_test):\n",
        "\n",
        "  \"\"\"\n",
        "  Standard Scale test and train data\n",
        "  Z - Score normalization\n",
        "  \"\"\"\n",
        "  minmax_scaler = MinMaxScaler()\n",
        "  x_train_scaled = pd.DataFrame(\n",
        "      minmax_scaler.fit_transform(x_train),\n",
        "      columns=x_train.columns\n",
        "  )\n",
        "  x_test_scaled = pd.DataFrame(\n",
        "      minmax_scaler.transform(x_test),\n",
        "      columns = x_test.columns\n",
        "  )\n",
        "  return x_train_scaled, x_test_scaled\n",
        "x_train_scaled, x_test_scaled = scale_datasets(x_train, x_test)\n",
        "\n",
        "\n",
        "# Creating model using the Sequential in tensorflow\n",
        "def build_model_using_sequential():\n",
        "  model = Sequential([\n",
        "    Dense(64, input_shape = [13], kernel_initializer='normal', activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(32, kernel_initializer='normal',  kernel_regularizer='l2', activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(16, kernel_initializer='normal', kernel_regularizer='l2', activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(8, kernel_initializer='normal', kernel_regularizer='l2', activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, kernel_initializer='normal', activation='linear')\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = build_model_using_sequential()"
      ],
      "metadata": {
        "id": "lIiNsztHpEkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "msle = MeanSquaredLogarithmicError()\n",
        "\n",
        "model.compile(\n",
        "    loss=msle,\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    metrics=[msle]\n",
        ")\n",
        "\n",
        "# Hyperparameter tuning ranges\n",
        "epochs_range = range(100, 1001, 100)\n",
        "batch_sizes_range = [32, 64, 128, 256, 512]\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for epochs in epochs_range:\n",
        "    for batch_size in batch_sizes_range:\n",
        "        print(f\"Training model with epochs={epochs}, batch_size={batch_size}\")\n",
        "\n",
        "        # Train the model with the current hyperparameters\n",
        "        history = model.fit(\n",
        "            x_train_scaled.values,\n",
        "            y_train.values,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=0.2,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Print the loss and metrics for the last epoch\n",
        "        print(f\"Final Loss: {history.history['loss'][-1]}\")\n",
        "        print(f\"Final Mean Squared Logarithmic Error: {history.history['mean_squared_logarithmic_error'][-1]}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "22qKKcQ3pEhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "history = model.fit(\n",
        "    x_train_scaled.values,\n",
        "    y_train.values,\n",
        "    epochs=1000,\n",
        "    batch_size=256,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "T3_hFOtkpaik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msle_score = model.evaluate(x_train_scaled, y_train, verbose=0)\n",
        "print(\"MSLE score:\", msle_score)"
      ],
      "metadata": {
        "id": "mUxqLwkDpdlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, key):\n",
        "  plt.plot(history.history[key])\n",
        "  plt.plot(history.history['val_'+key])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(key)\n",
        "  plt.legend([key, 'val_'+key])\n",
        "  plt.show()\n",
        "# Plot the history\n",
        "plot_history(history, 'mean_squared_logarithmic_error')"
      ],
      "metadata": {
        "id": "op6OMFcWpe8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test['prediction'] = model.predict(x_test_scaled)\n",
        "x_test"
      ],
      "metadata": {
        "id": "Ylt__3e4pkh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = x_test['prediction']\n",
        "test = test_features['Speed']\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test, predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "lims = [1, 15]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "metadata": {
        "id": "oVZm1By4pojO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJPXWxGOptPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}